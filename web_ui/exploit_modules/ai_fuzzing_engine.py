"""
AI-Driven Context-Aware Fuzzing Engine
Uses Gemini to understand API business logic and generate semantic exploits
Based on 2026 LLM-Assisted Security Testing Research
"""

import json
import re
from typing import Dict, List, Optional, Any
from datetime import datetime
import urllib.parse


class ContextAwareFuzzingEngine:
    """
    Leverages Gemini's understanding of API documentation to generate
    business-logic-violating requests that traditional fuzzers miss.
    """
    
    def __init__(self, gemini_client):
        self.client = gemini_client
        self.model = "gemini-2.0-flash-exp"
        self.vulnerabilities_found = []
    
    def semantic_api_fuzzing(self, openapi_spec: Dict, target_endpoint: str) -> Dict:
        """
        Generates business-logic-violating API requests based on OpenAPI/Swagger spec.
        
        Unlike traditional fuzzing (random bytes), this understands:
        - Price manipulation opportunities
        - Quantity overflow attacks
        - Role-based access control bypasses
        - Race condition exploitation
        """
        prompt = f"""
You are an expert API security researcher analyzing OpenAPI specifications for business logic vulnerabilities.

OPENAPI SPECIFICATION:
```json
{json.dumps(openapi_spec, indent=2)[:8000]}
```

TARGET ENDPOINT: {target_endpoint}

FUZZING OBJECTIVES - Generate attacks that:

1. **Price Manipulation:**
   - Negative prices
   - Zero prices for premium items
   - Integer overflow in pricing calculations
   - Currency mismatch exploitation

2. **Quantity Exploitation:**
   - Negative quantities (refund abuse)
   - Massive quantities (inventory exhaustion)
   - Fractional quantities where integers expected
   - Quantity race conditions (buy same item twice)

3. **Authorization Bypass:**
   - Parameter injection to change user IDs
   - Role escalation via header manipulation
   - IDOR via predictable resource IDs
   - JWT claim manipulation

4. **Race Conditions:**
   - Concurrent requests to exploit TOCTOU bugs
   - Double-spend attacks
   - Parallel discount code redemption

5. **Business Logic Violations:**
   - Apply discount codes multiple times
   - Access resources before payment completes
   - Skip required workflow steps
   - Exploit state machine flaws

OUTPUT (JSON):
{{
  "test_cases": [
    {{
      "name": "Negative price injection",
      "method": "POST",
      "url": "/api/v1/orders",
      "headers": {{"Authorization": "Bearer ..."}},
      "body": {{"item_id": 123, "quantity": 1, "price": -99.99}},
      "expected_vulnerability": "Accepts negative price, gives refund instead of charge",
      "severity": "critical",
      "business_impact": "Financial loss"
    }}
  ],
  "exploitation_code": "Complete Python requests code to execute all test cases"
}}

Generate 20+ diverse test cases covering all vulnerability categories.
"""
        
        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt
            )
            
            result_text = response.text
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            
            fuzzing_results = json.loads(result_text)
            
            # Store vulnerabilities
            for test_case in fuzzing_results.get("test_cases", []):
                self.vulnerabilities_found.append({
                    "timestamp": datetime.utcnow().isoformat(),
                    "type": "semantic_api_fuzzing",
                    "endpoint": target_endpoint,
                    **test_case
                })
            
            return fuzzing_results
        except Exception as e:
            return {"error": str(e), "test_cases": []}
    
    def graphql_complexity_attack(self, graphql_schema: str, target_query: str = None) -> Dict:
        """
        Generates deeply nested GraphQL queries to trigger DoS via query complexity.
        
        Attack vectors:
        - Circular references causing infinite loops
        - Deeply nested queries (1000+ levels)
        - Batched queries amplification
        - Alias-based multiplication attacks
        """
        prompt = f"""
Analyze this GraphQL schema for query complexity exploitation:

GRAPHQL SCHEMA:
```graphql
{graphql_schema[:5000]}
```

ATTACK GENERATION:

1. **Depth Attacks:**
   - Generate queries nested 500+ levels deep
   - Exploit circular references (User -> Posts -> User -> Posts ...)
   - Max out resolver execution time

2. **Breadth Attacks:**
   - Request all fields simultaneously
   - Use aliases to multiply same query 1000x times
   - Batch multiple expensive queries

3. **Combination Attacks:**
   - Deep + Wide queries (nested 100 levels, each requesting 50 fields)
   - Recursive relationships with no limit

4. **Resource Exhaustion:**
   - Queries that trigger N+1 database problems
   - Expensive computed fields (aggregations, sorting large datasets)

OUTPUT (JSON):
{{
  "attack_queries": [
    {{
      "name": "Recursive user query (500 levels)",
      "query": "{{ user {{ posts {{ author {{ posts {{ ... }} }} }} }} }}",
      "expected_impact": "CPU exhaustion, query timeout",
      "severity": "high"
    }}
  ],
  "exploitation_script": "Python code with GraphQL client to execute attacks"
}}

Generate 10+ attack queries of varying complexity.
"""
        
        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt
            )
            
            result_text = response.text
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            
            return json.loads(result_text)
        except Exception as e:
            return {"error": str(e)}
    
    def auth_flow_bypass_generator(self, auth_flow_description: str, api_endpoints: List[str]) -> Dict:
        """
        Analyzes multi-step authentication flows to find bypass opportunities.
        
        Common bypasses:
        - Skip intermediate steps (go straight to protected resource)
        - Replay tokens from different stages
        - Race condition in state validation
        - Parameter pollution to confuse state machine
        """
        prompt = f"""
Analyze this authentication/authorization flow for bypass vulnerabilities:

AUTH FLOW DESCRIPTION:
{auth_flow_description}

API ENDPOINTS INVOLVED:
{chr(10).join(api_endpoints)}

BYPASS TECHNIQUES:

1. **Step Skipping:**
   - Can we access /complete-payment before /verify-otp?
   - Does the system properly validate previous steps?

2. **State Confusion:**
   - Replay tokens from different sessions
   - Mix parameters from different workflow stages
   - Exploit inconsistent state validation

3. **Race Conditions:**
   - Concurrent requests to bypass one-time checks
   - TOCTOU in multi-step verification

4. **Parameter Injection:**
   - Inject 'admin=true' in hidden parameters
   - Modify user_id during workflow
   - Tamper with JWT claims between steps

5. **Token Reuse:**
   - Reuse verification codes across accounts
   - Replay authentication tokens after logout

OUTPUT (JSON):
{{
  "bypass_scenarios": [
    {{
      "name": "Skip email verification step",
      "attack_sequence": [
        "POST /register -> get user_id",
        "POST /complete-profile -> skip /verify-email",
        "Access protected resources without verification"
      ],
      "exploitation_code": "Python requests sequence",
      "success_probability": "high",
      "detection_difficulty": "medium"
    }}
  ],
  "recommended_tests": ["..."]
}}

Generate comprehensive authentication bypass attack chains.
"""
        
        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt
            )
            
            result_text = response.text
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            
            return json.loads(result_text)
        except Exception as e:
            return {"error": str(e)}
    
    def parameter_pollution_ai(self, http_request_sample: str) -> Dict:
        """
        Generates HTTP Parameter Pollution (HPP) attacks using AI understanding of parsing.
        
        Exploits differences in how:
        - Load balancers parse parameters
        - Application servers parse parameters  
        - Databases interpret queries
        """
        prompt = f"""
Analyze this HTTP request for Parameter Pollution opportunities:

SAMPLE REQUEST:
```http
{http_request_sample}
```

HPP ATTACK VECTORS:

1. **Duplicate Parameters:**
   - ?user_id=123&user_id=456 (which one is used?)
   - Exploit inconsistent parsing (load balancer vs. app server)

2. **Encoding Variations:**
   - URL encoding: %75ser_id (may bypass WAF)
   - Double encoding: %2575ser_id
   - Unicode variations: u\u0073er_id

3. **Array Injection:**
   - Convert scalar to array: user_id[]=123&user_id[]=456
   - Exploit type confusion bugs

4. **Delimiter Confusion:**
   - ?filters=name;admin (semicolon vs. ampersand)
   - ?data={"role":"user"}&data={"role":"admin"}

5. **Case Sensitivity:**
   - User_Id vs. user_id vs. USER_ID
   - Exploit case-insensitive matching bugs

OUTPUT (JSON):
{{
  "pollution_attacks": [
    {{
      "technique": "Duplicate user_id parameter",
      "malicious_request": "GET /api/user?user_id=victim&user_id=attacker",
      "expected_behavior": "Load balancer checks victim, app uses attacker",
      "severity": "critical"
    }}
  ],
  "exploitation_script": "Python requests with pollution payloads"
}}
"""
        
        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt
            )
            
            result_text = response.text
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            
            return json.loads(result_text)
        except Exception as e:
            return {"error": str(e)}
    
    def generate_smart_sqli_payloads(self, input_context: Dict) -> List[str]:
        """
        Uses Gemini to generate context-aware SQL injection payloads.
        
        Unlike static wordlists, adapts to:
        - Database type (MySQL, PostgreSQL, MSSQL, Oracle)
        - Input field context (login, search, filter)
        - WAF fingerprint (bypass specific filters)
        """
        prompt = f"""
Generate advanced SQL injection payloads for this specific context:

INPUT CONTEXT:
```json
{json.dumps(input_context, indent=2)}
```

PAYLOAD REQUIREMENTS:

1. **Database-Specific Syntax:**
   - If MySQL: Use UNION SELECT, BENCHMARK, SLEEP
   - If PostgreSQL: Use pg_sleep, COPY, lo_import
   - If MSSQL: Use xp_cmdshell, WAITFOR DELAY
   - If Oracle: Use UTL_HTTP, DBMS_SCHEDULER

2. **WAF Bypass Techniques:**
   - Encoding: HEX, Base64, URL encoding
   - Obfuscation: /**/ comments, alternative keywords
   - Case variation: SeLeCt, %53elect
   - String concatenation: 'adm'||'in', CONCAT('ad','min')

3. **Context-Aware Injection:**
   - If numeric context: ' OR 1=1-- vs. 1 OR 1=1--
   - If string context: ' OR 'a'='a
   - If JSON context: {"$gt": ""} (NoSQL injection)

4. **Advanced Techniques:**
   - Time-based blind SQLi with binary search
   - Boolean-based extraction
   - Error-based information disclosure
   - Second-order SQL injection

OUTPUT: JSON array of 50+ payloads ranked by success probability.
{{
  "payloads": [
    {{
      "payload": "' UNION SELECT password FROM users WHERE username='admin'--",
      "technique": "UNION-based extraction",
      "context": "string input, MySQL database",
      "stealth_level": "medium"
    }}
  ]
}}
"""
        
        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt
            )
            
            result_text = response.text
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            
            result = json.loads(result_text)
            return result.get("payloads", [])
        except Exception as e:
            return [{"error": str(e)}]
    
    def ai_csrf_token_predictor(self, csrf_samples: List[str]) -> Dict:
        """
        Analyzes CSRF token patterns to predict future tokens.
        
        Weak CSRF implementations use:
        - Timestamp-based tokens
        - Predictable random number generators
        - Hash of predictable data (user_id + timestamp)
        """
        prompt = f"""
Analyze these CSRF token samples to identify prediction patterns:

CSRF TOKEN SAMPLES:
{chr(10).join(csrf_samples)}

ANALYSIS TASKS:

1. **Entropy Analysis:**
   - Are tokens truly random or based on predictable data?
   - Calculate Shannon entropy

2. **Pattern Detection:**
   - Timestamp-based (decode and verify)
   - Sequential (incrementing values)
   - Hash-based (identify hashing algorithm)

3. **Prediction Algorithm:**
   - If predictable, generate next 100 tokens
   - Calculate success probability

4. **Bypass Techniques:**
   - Token reuse across sessions
   - Token fixation attacks
   - Missing token validation

OUTPUT (JSON):
{{
  "pattern_detected": "MD5 hash of user_id + timestamp (seconds precision)",
  "predictability": "high",
  "next_tokens": ["predicted_token_1", "..."],
  "bypass_methods": ["Reuse token from parallel session"],
  "exploitation_code": "Python script to generate valid tokens"
}}
"""
        
        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt
            )
            
            result_text = response.text
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            
            return json.loads(result_text)
        except Exception as e:
            return {"error": str(e)}
    
    def get_vulnerabilities(self) -> List[Dict]:
        """Returns all vulnerabilities found during fuzzing."""
        return self.vulnerabilities_found
    
    def generate_fuzzing_report(self) -> str:
        """Creates comprehensive fuzzing report."""
        report = "# AI-Driven Fuzzing Report\n\n"
        report += f"**Generated:** {datetime.utcnow().isoformat()}\n"
        report += f"**Total Vulnerabilities:** {len(self.vulnerabilities_found)}\n\n"
        
        severity_counts = {}
        for vuln in self.vulnerabilities_found:
            severity = vuln.get("severity", "unknown")
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        report += "## Severity Distribution\n"
        for severity, count in sorted(severity_counts.items()):
            report += f"- **{severity.upper()}:** {count}\n"
        
        report += "\n## Detailed Findings\n\n"
        for vuln in self.vulnerabilities_found:
            report += f"### {vuln.get('name', 'Unnamed Vulnerability')}\n"
            report += f"- **Severity:** {vuln.get('severity', 'unknown')}\n"
            report += f"- **Type:** {vuln.get('type', 'unknown')}\n"
            report += f"- **Description:** {vuln.get('expected_vulnerability', '')}\n\n"
        
        return report


# Example Usage
if __name__ == "__main__":
    from gemini_config import get_gemini_client
    
    client = get_gemini_client()
    fuzzer = ContextAwareFuzzingEngine(client)
    
    # Example: Semantic API fuzzing
    openapi_spec = {
        "paths": {
            "/api/v1/orders": {
                "post": {
                    "parameters": [
                        {"name": "item_id", "type": "integer"},
                        {"name": "quantity", "type": "integer"},
                        {"name": "price", "type": "number"}
                    ]
                }
            }
        }
    }
    
    results = fuzzer.semantic_api_fuzzing(openapi_spec, "/api/v1/orders")
    print(json.dumps(results, indent=2))
